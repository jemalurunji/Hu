{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN25R/RdnU9M8DHZnCpNFAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jemalurunji/Hu/blob/main/Question_G.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://drive.google.com/u/0/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA -O lamb.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnIb0UqQ9Qug",
        "outputId": "5d22a15b-f9ba-4579-b2d8-73a4fca32a9e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-13 13:23:26--  https://drive.google.com/u/0/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.132.100, 74.125.132.139, 74.125.132.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.132.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA [following]\n",
            "--2024-05-13 13:23:26--  https://drive.google.com/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA [following]\n",
            "--2024-05-13 13:23:26--  https://drive.usercontent.google.com/download?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.196.132, 2607:f8b0:4001:c64::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.196.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA [following]\n",
            "--2024-05-13 13:23:26--  https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Resolving accounts.google.com (accounts.google.com)... 173.194.206.84, 2607:f8b0:4001:c16::54\n",
            "Connecting to accounts.google.com (accounts.google.com)|173.194.206.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/InteractiveLogin?continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&passive=1209600&service=wise&ifkv=AaSxoQwByfbnR-C4WGzvgfOwqdNXOuojcyrJfPIDBSABXdhHLSuG5xHpFW7rcmHIRkCQDmMc2QqpHQ [following]\n",
            "--2024-05-13 13:23:26--  https://accounts.google.com/InteractiveLogin?continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&passive=1209600&service=wise&ifkv=AaSxoQwByfbnR-C4WGzvgfOwqdNXOuojcyrJfPIDBSABXdhHLSuG5xHpFW7rcmHIRkCQDmMc2QqpHQ\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&ifkv=AaSxoQwqcry_ag9jQcGhtdk3pFjdSqsWRHGK3GwTW061nKb6DOnM6BwkVSLFDhYEZvmEaQgj35iM_Q&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S1895866733%3A1715606606559053 [following]\n",
            "--2024-05-13 13:23:26--  https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&ifkv=AaSxoQwqcry_ag9jQcGhtdk3pFjdSqsWRHGK3GwTW061nKb6DOnM6BwkVSLFDhYEZvmEaQgj35iM_Q&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S1895866733%3A1715606606559053\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘lamb.csv’\n",
            "\n",
            "lamb.csv                [ <=>                ] 164.34K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-05-13 13:23:26 (3.82 MB/s) - ‘lamb.csv’ saved [168285]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file with the correct number of columns\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)])"
      ],
      "metadata": {
        "id": "ezh0drI-McoL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xySYEFHdIasl",
        "outputId": "03cc47fe-29ae-4f35-bfcf-12190d0ad4c9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file from Google Drive\n",
        "!wget https://drive.google.com/u/0/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA -O custom_stopwords.txt\n",
        "# Read the custom stopwords file\n",
        "with open('custom_stopwords.txt', 'r') as file:\n",
        "    custom_stopwords = file.read().splitlines()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7oqC57zAcU3",
        "outputId": "606e9ba0-d600-451a-b38f-6d7601c36f88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-13 12:55:03--  https://drive.google.com/u/0/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.132.100, 74.125.132.102, 74.125.132.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.132.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA [following]\n",
            "--2024-05-13 12:55:03--  https://drive.google.com/uc?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA [following]\n",
            "--2024-05-13 12:55:03--  https://drive.usercontent.google.com/download?id=1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.196.132, 2607:f8b0:4001:c1a::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.196.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA [following]\n",
            "--2024-05-13 12:55:04--  https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA\n",
            "Resolving accounts.google.com (accounts.google.com)... 209.85.145.84, 2607:f8b0:4001:c06::54\n",
            "Connecting to accounts.google.com (accounts.google.com)|209.85.145.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/InteractiveLogin?continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&passive=1209600&service=wise&ifkv=AaSxoQwT3LCP-DCWh5jOHmICtCCy2JuGEV7n25ijxZZfvc8tSqep56Odd87WDUU7eNCPymRHpczl [following]\n",
            "--2024-05-13 12:55:04--  https://accounts.google.com/InteractiveLogin?continue=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https://drive.usercontent.google.com/download?id%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&passive=1209600&service=wise&ifkv=AaSxoQwT3LCP-DCWh5jOHmICtCCy2JuGEV7n25ijxZZfvc8tSqep56Odd87WDUU7eNCPymRHpczl\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&ifkv=AaSxoQwpZVUt9BVluVI910qx07omA_VxQ-mFvDGCXSK2Ud2XUE4LrM9qsQIs5QvHl-UdzftZy5Lr&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-586736751%3A1715604904087905 [following]\n",
            "--2024-05-13 12:55:04--  https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&followup=https%3A%2F%2Fdrive.usercontent.google.com%2Fdownload%3Fid%3D1CS0a7MDd65NCTZlxhl_35zSfRV3OohiA&ifkv=AaSxoQwpZVUt9BVluVI910qx07omA_VxQ-mFvDGCXSK2Ud2XUE4LrM9qsQIs5QvHl-UdzftZy5Lr&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-586736751%3A1715604904087905\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘custom_stopwords.txt’\n",
            "\n",
            "custom_stopwords.tx     [ <=>                ] 164.09K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-05-13 12:55:04 (3.28 MB/s) - ‘custom_stopwords.txt’ saved [168024]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "# Download necessary resources from NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Read the custom stopwords file\n",
        "with open('custom_stopwords.txt', 'r') as file:\n",
        "    custom_stopwords = file.read().splitlines()\n",
        "# Tokenize function\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):  # Check if the value is a string\n",
        "        tokens = word_tokenize(text)\n",
        "        return [word for word in tokens if word.lower() not in custom_stopwords]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('lamb.csv')\n",
        "# Extract the paragraphs, questions, answers, and fact/non-fact labels from the dataframe\n",
        "paragraphs = df['Paragraph'].astype(str).tolist()\n",
        "questions = df['Question'].astype(str).tolist()\n",
        "answers = df['Answer'].astype(str).tolist()\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() if isinstance(sentence, str) else [] for sentence in corpus]\n",
        "# Create training data for skip-gram\n",
        "skip_gram_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    skip_gram_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)])\n",
        "\n",
        "# Create training data for CBOW\n",
        "cbow_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    cbow_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)] + tokenized_corpus[i + len(paragraphs) * 2])\n",
        "# Train Word2Vec model using skip-gram\n",
        "skip_gram_model = Word2Vec(skip_gram_data, sg=1)\n",
        "# Train Word2Vec model using CBOW\n",
        "cbow_model = Word2Vec(cbow_data, sg=0)\n",
        "# Print the word vectors\n",
        "print(\"Word Vectors (Skip-gram):\")\n",
        "for word in skip_gram_model.wv.index_to_key:\n",
        "    print(word, skip_gram_model.wv.get_vector(word))\n",
        "print(\"\\nWord Vectors (CBOW):\")\n",
        "for word in cbow_model.wv.index_to_key:\n",
        "    print(word, cbow_model.wv.get_vector(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "w9CoCK1YAYP-",
        "outputId": "c982e9fc-321f-4dcd-c396-51876e5b3c89"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 356 fields in line 7, saw 3590\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-9c0558f2b770>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Read the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lamb.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# Extract the paragraphs, questions, answers, and fact/non-fact labels from the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 356 fields in line 7, saw 3590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UZ8SOON98Giz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ekUO0DQd7qDU"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file with the correct number of columns\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):  # Check if the value is a string\n",
        "        tokens = word_tokenize(text)\n",
        "        return [word for word in tokens if word.lower() not in custom_stopwords]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "\n",
        "# Extract the paragraphs, questions, answers, and fact/non-fact labels from the dataframe\n",
        "paragraphs = df.iloc[:, 0].astype(str).tolist()\n",
        "questions = df.iloc[:, 1].astype(str).tolist()\n",
        "answers = df.iloc[:, 2].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() if isinstance(sentence, str) else [] for sentence in corpus]\n",
        "\n",
        "# Create training data for skip-gram\n",
        "skip_gram_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    skip_gram_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)])\n",
        "\n",
        "# Create training data for CBOW\n",
        "cbow_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    cbow_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)] + tokenized_corpus[i + len(paragraphs) * 2])\n",
        "\n",
        "# Train Word2Vec model using skip-gram\n",
        "skip_gram_model = Word2Vec(skip_gram_data, sg=1)\n",
        "\n",
        "# Train Word2Vec model using CBOW\n",
        "cbow_model = Word2Vec(cbow_data, sg=0)\n",
        "\n",
        "# Save the Word2Vec models\n",
        "skip_gram_model.save('skip_gram_model.bin')\n",
        "cbow_model.save('cbow_model.bin')"
      ],
      "metadata": {
        "id": "7BUn8O1q8G8X"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):  # Check if the value is a string\n",
        "        tokens = word_tokenize(text)\n",
        "        return [word for word in tokens if word.lower() not in custom_stopwords]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "\n",
        "# Extract the paragraphs, questions, answers, and fact/non-fact labels from the dataframe\n",
        "paragraphs = df['1'].astype(str).tolist()\n",
        "questions = df['2'].astype(str).tolist()\n",
        "answers = df['3'].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() if isinstance(sentence, str) else [] for sentence in corpus]\n",
        "\n",
        "# Create training data for skip-gram\n",
        "skip_gram_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    skip_gram_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)])\n",
        "\n",
        "# Create training data for CBOW\n",
        "cbow_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    cbow_data.append(tokenized_corpus[i] + tokenized_corpus[i + 1] + tokenized_corpus[i + 2])"
      ],
      "metadata": {
        "id": "13EXZs8sVvdE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "\n",
        "# Extract the paragraphs, questions, answers from the dataframe\n",
        "paragraphs = df['1'].astype(str).tolist()  # Change 'Paragraph' to '1'\n",
        "questions = df['2'].astype(str).tolist()\n",
        "answers = df['3'].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# ... rest of the code remains the same\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Define the desired embedding dimensionality\n",
        "embedding_dim = 100  # You can choose 100, 200, or any other desired dimension\n",
        "\n",
        "# Create training data for CBOW\n",
        "cbow_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    cbow_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)] + tokenized_corpus[i + len(paragraphs) * 2])\n",
        "\n",
        "# Train Word2Vec model using skip-gram with specified embedding dimension\n",
        "skip_gram_model = Word2Vec(skip_gram_data, sg=1, vector_size=embedding_dim)\n",
        "\n",
        "# Train Word2Vec model using CBOW with specified embedding dimension\n",
        "cbow_model = Word2Vec(cbow_data, sg=0, vector_size=embedding_dim)\n",
        "\n",
        "# Save the Word2Vec models with the specified dimensionality\n",
        "skip_gram_model.save('skip_gram_model_dim_{}.bin'.format(embedding_dim))\n",
        "cbow_model.save('cbow_model_dim_{}.bin'.format(embedding_dim))\n",
        "\n",
        "# Print the word vectors\n",
        "print(\"Word Vectors (Skip-gram):\")\n",
        "for word in skip_gram_model.wv.index_to_key:\n",
        "    print(word, skip_gram_model.wv.get_vector(word))\n",
        "\n",
        "print(\"\\nWord Vectors (CBOW):\")\n",
        "for word in cbow_model.wv.index_to_key:\n",
        "    print(word, cbow_model.wv.get_vector(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPW6z4zwWt_j",
        "outputId": "9402ed3d-69df-4cd4-906d-e7a0fa103b8e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Vectors (Skip-gram):\n",
            "var [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
            "nan [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "*/ [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "  7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            " -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "  9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "  5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            " -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "  7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            " -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            " -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            " -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "  3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            " -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            " -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            " -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "  4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            " -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            " -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "  4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "  9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "  1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "  1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "  8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "  9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            "Apache-2.0 [-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
            "  4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
            "  6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
            "  3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
            "  8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
            "  1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
            " -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
            "  2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
            " -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
            "  9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
            "  3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
            "  7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
            " -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
            " -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
            "  1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
            "  2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
            "  4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
            " -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
            " -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
            " -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
            " -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
            " -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
            " -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
            " -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
            "  5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n",
            "SPDX-License-Identifier: [-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n",
            "  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n",
            " -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n",
            "  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n",
            " -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n",
            "  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n",
            " -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n",
            " -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n",
            "  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n",
            " -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n",
            "  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n",
            "  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n",
            " -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n",
            "  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n",
            " -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n",
            "  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n",
            "  0.00620989  0.00481889  0.00078719  0.00301345]\n",
            "\n",
            "Word Vectors (CBOW):\n",
            "nan [-5.3599576e-04  2.3618268e-04  5.1031811e-03  9.0090176e-03\n",
            " -9.3027530e-03 -7.1164612e-03  6.4585819e-03  8.9725042e-03\n",
            " -5.0154147e-03 -3.7630494e-03  7.3800110e-03 -1.5335401e-03\n",
            " -4.5365617e-03  6.5539908e-03 -4.8602140e-03 -1.8159003e-03\n",
            "  2.8762536e-03  9.9197880e-04 -8.2847234e-03 -9.4486726e-03\n",
            "  7.3114745e-03  5.0701466e-03  6.7572175e-03  7.6259393e-04\n",
            "  6.3509271e-03 -3.4053151e-03 -9.4652857e-04  5.7682772e-03\n",
            " -7.5214347e-03 -3.9359811e-03 -7.5113443e-03 -9.2991180e-04\n",
            "  9.5379790e-03 -7.3188636e-03 -2.3337910e-03 -1.9379033e-03\n",
            "  8.0769230e-03 -5.9305397e-03  4.5404217e-05 -4.7538253e-03\n",
            " -9.6033132e-03  5.0069895e-03 -8.7594511e-03 -4.3916032e-03\n",
            " -3.5288278e-05 -2.9624463e-04 -7.6610539e-03  9.6144788e-03\n",
            "  4.9819695e-03  9.2328908e-03 -8.1577506e-03  4.4956431e-03\n",
            " -4.1366871e-03  8.2475814e-04  8.4984899e-03 -4.4620214e-03\n",
            "  4.5172949e-03 -6.7869741e-03 -3.5485127e-03  9.3982993e-03\n",
            " -1.5776062e-03  3.2123216e-04 -4.1406881e-03 -7.6823980e-03\n",
            " -1.5080689e-03  2.4698614e-03 -8.8797597e-04  5.5332640e-03\n",
            " -2.7428227e-03  2.2602386e-03  5.4554595e-03  8.3457706e-03\n",
            " -1.4536596e-03 -9.2080878e-03  4.3704626e-03  5.7188864e-04\n",
            "  7.4417931e-03 -8.1343576e-04 -2.6381763e-03 -8.7527670e-03\n",
            " -8.5639174e-04  2.8263086e-03  5.4011326e-03  7.0523489e-03\n",
            " -5.7028886e-03  1.8588277e-03  6.0884240e-03 -4.7980226e-03\n",
            " -3.1070989e-03  6.7976434e-03  1.6316123e-03  1.8993816e-04\n",
            "  3.4735398e-03  2.1783641e-04  9.6182497e-03  5.0604437e-03\n",
            " -8.9172395e-03 -7.0411288e-03  9.0149010e-04  6.3924603e-03]\n",
            "var [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "not [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "  7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            " -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "  9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "  5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            " -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "  7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            " -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            " -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            " -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "  3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            " -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            " -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            " -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "  4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            " -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            " -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "  4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "  9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "  1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "  1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "  8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "  9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            "*/ [-8.2427636e-03  9.2994273e-03 -1.9734078e-04 -1.9667214e-03\n",
            "  4.6030735e-03 -4.0957900e-03  2.7435382e-03  6.9405753e-03\n",
            "  6.0651479e-03 -7.5110784e-03  9.3828738e-03  4.6717408e-03\n",
            "  3.9658598e-03 -6.2431321e-03  8.4597263e-03 -2.1502927e-03\n",
            "  8.8254241e-03 -5.3619738e-03 -8.1299916e-03  6.8240068e-03\n",
            "  1.6716636e-03 -2.1982035e-03  9.5140859e-03  9.4939619e-03\n",
            " -9.7737079e-03  2.5050298e-03  6.1566713e-03  3.8728439e-03\n",
            "  2.0223262e-03  4.3025654e-04  6.7316263e-04 -3.8207187e-03\n",
            " -7.1396944e-03 -2.0893463e-03  3.9237752e-03  8.8186162e-03\n",
            "  9.2597166e-03 -5.9763473e-03 -9.4027268e-03  9.7641386e-03\n",
            "  3.4292014e-03  5.1664650e-03  6.2818327e-03 -2.8045566e-03\n",
            "  7.3227473e-03  2.8302707e-03  2.8705399e-03 -2.3797792e-03\n",
            " -3.1279556e-03 -2.3695750e-03  4.2759497e-03  7.6341508e-05\n",
            " -9.5845992e-03 -9.6655525e-03 -6.1476971e-03 -1.2885142e-04\n",
            "  1.9977130e-03  9.4315987e-03  5.5841622e-03 -4.2901314e-03\n",
            "  2.7821911e-04  4.9644099e-03  7.6980973e-03 -1.1447142e-03\n",
            "  4.3233526e-03 -5.8142603e-03 -8.0425158e-04  8.1004500e-03\n",
            " -2.3602524e-03 -9.6633732e-03  5.7796403e-03 -3.9293212e-03\n",
            " -1.2229719e-03  9.9799996e-03 -2.2560896e-03 -4.7570583e-03\n",
            " -5.3289519e-03  6.9808825e-03 -5.7090740e-03  2.1131248e-03\n",
            " -5.2557467e-03  6.1209304e-03  4.3576742e-03  2.6068154e-03\n",
            " -1.4914514e-03 -2.7459636e-03  8.9933760e-03  5.2155051e-03\n",
            " -2.1627289e-03 -9.4699413e-03 -7.4259955e-03 -1.0637360e-03\n",
            " -7.9473335e-04 -2.5629115e-03  9.6833864e-03 -4.5820483e-04\n",
            "  5.8732363e-03 -7.4480772e-03 -2.5060328e-03 -5.5494956e-03]\n",
            "Apache-2.0 [-0.00713924  0.00124128 -0.00717656 -0.00224439  0.00371913  0.0058328\n",
            "  0.00119845  0.00210319 -0.00411039  0.00722502 -0.00630657  0.00464729\n",
            " -0.00822001  0.00203651 -0.00497699 -0.0042478  -0.00310867  0.0056551\n",
            "  0.00579794 -0.00497477  0.0007736  -0.00849568  0.00781026  0.00925756\n",
            " -0.00274238  0.00080018  0.00074678  0.00547816 -0.00860626  0.00058434\n",
            "  0.00686921  0.00223147  0.00112479 -0.00932244  0.00848239 -0.00626396\n",
            " -0.00299189  0.00349345 -0.00077287  0.00141139  0.00178178 -0.00682861\n",
            " -0.00972492  0.00904038  0.00619824 -0.00691286  0.00340332  0.0002063\n",
            "  0.00475382 -0.00711972  0.00402681  0.00434758  0.009957   -0.00447396\n",
            " -0.00138916 -0.00731746 -0.00969764 -0.00908023 -0.00102272 -0.00650311\n",
            "  0.00484969 -0.00616389  0.00251925  0.00073917 -0.00339209 -0.0009793\n",
            "  0.00997908  0.00914626 -0.00446197  0.00908285 -0.00564145  0.00593108\n",
            " -0.00309729  0.00343172  0.0030173   0.00690036 -0.00237379  0.00877519\n",
            "  0.0075892  -0.00954786 -0.00800837 -0.00763765  0.00292354 -0.00279444\n",
            " -0.00692974 -0.00812828  0.0083096   0.00199047 -0.00932817 -0.00479275\n",
            "  0.0031366  -0.00471323  0.00528093 -0.0042335   0.00264234 -0.00804554\n",
            "  0.00620976  0.00481848  0.00078716  0.0030135 ]\n",
            "SPDX-License-Identifier: [-8.7274825e-03  2.1301615e-03 -8.7354420e-04 -9.3190884e-03\n",
            " -9.4281426e-03 -1.4107180e-03  4.4324086e-03  3.7040710e-03\n",
            " -6.4986930e-03 -6.8730675e-03 -4.9994122e-03 -2.2868442e-03\n",
            " -7.2502876e-03 -9.6033178e-03 -2.7436293e-03 -8.3628409e-03\n",
            " -6.0388758e-03 -5.6709289e-03 -2.3441375e-03 -1.7069972e-03\n",
            " -8.9569986e-03 -7.3519943e-04  8.1525063e-03  7.6904297e-03\n",
            " -7.2061159e-03 -3.6668312e-03  3.1185520e-03 -9.5707225e-03\n",
            "  1.4764392e-03  6.5244664e-03  5.7464195e-03 -8.7630618e-03\n",
            " -4.5171441e-03 -8.1401607e-03  4.5956374e-05  9.2636338e-03\n",
            "  5.9733056e-03  5.0673080e-03  5.0610625e-03 -3.2429171e-03\n",
            "  9.5521836e-03 -7.3564244e-03 -7.2703874e-03 -2.2653891e-03\n",
            " -7.7856064e-04 -3.2161034e-03 -5.9258583e-04  7.4888230e-03\n",
            " -6.9751858e-04 -1.6249407e-03  2.7443992e-03 -8.3591007e-03\n",
            "  7.8558037e-03  8.5361041e-03 -9.5840869e-03  2.4462664e-03\n",
            "  9.9049713e-03 -7.6658037e-03 -6.9669187e-03 -7.7365171e-03\n",
            "  8.3959233e-03 -6.8133592e-04  9.1444086e-03 -8.1582209e-03\n",
            "  3.7430846e-03  2.6350426e-03  7.4271322e-04  2.3276759e-03\n",
            " -7.4690939e-03 -9.3583735e-03  2.3545765e-03  6.1484552e-03\n",
            "  7.9856887e-03  5.7358947e-03 -7.7733636e-04  8.3061643e-03\n",
            " -9.3363142e-03  3.4061326e-03  2.6675343e-04  3.8572443e-03\n",
            "  7.3857834e-03 -6.7251669e-03  5.5844807e-03 -9.5222248e-03\n",
            " -8.0445886e-04 -8.6887367e-03 -5.0986730e-03  9.2892265e-03\n",
            " -1.8582619e-03  2.9144264e-03  9.0712793e-03  8.9381328e-03\n",
            " -8.2084350e-03 -3.0123137e-03  9.8866057e-03  5.1044310e-03\n",
            " -1.5880871e-03 -8.6920215e-03  2.9615164e-03 -6.6758976e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "# Extract the paragraphs, questions, answers from the dataframe\n",
        "paragraphs = df['1'].astype(str).tolist()  # Change 'Paragraph' to '1'\n",
        "questions = df['2'].astype(str).tolist()\n",
        "answers = df['3'].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Define the desired embedding dimensionality\n",
        "embedding_dim = 100  # You can choose 100, 200, or any other desired dimension\n",
        "\n",
        "# Create training data for CBOW\n",
        "cbow_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    cbow_data.append(tokenized_corpus[i] + tokenized_corpus[i + len(paragraphs)] + tokenized_corpus[i + len(paragraphs) * 2])\n",
        "\n",
        "# Train Word2Vec model using skip-gram with specified embedding dimension\n",
        "skip_gram_model = Word2Vec(skip_gram_data, sg=1, vector_size=embedding_dim)\n",
        "\n",
        "# Train Word2Vec model using CBOW with specified embedding dimension\n",
        "cbow_model = Word2Vec(cbow_data, sg=0, vector_size=embedding_dim)\n",
        "\n",
        "# Extract the embedding matrix from the Word2Vec models\n",
        "embedding_matrix_skip_gram = skip_gram_model.wv.vectors\n",
        "embedding_matrix_cbow = cbow_model.wv.vectors\n",
        "\n",
        "# Save the Word2Vec models with the specified dimensionality\n",
        "skip_gram_model.save('skip_gram_model_dim_{}.bin'.format(embedding_dim))\n",
        "cbow_model.save('cbow_model_dim_{}.bin'.format(embedding_dim))\n",
        "\n",
        "# Print the word vectors\n",
        "print(\"Word Vectors (Skip-gram):\")\n",
        "for word in skip_gram_model.wv.index_to_key:\n",
        "    print(word, skip_gram_model.wv.get_vector(word))\n",
        "\n",
        "print(\"\\nWord Vectors (CBOW):\")\n",
        "for word in cbow_model.wv.index_to_key:\n",
        "    print(word, cbow_model.wv.get_vector(word))\n",
        "\n",
        "# Print the embedding matrices\n",
        "print(\"\\nEmbedding Matrix (Skip-gram):\")\n",
        "print(embedding_matrix_skip_gram)\n",
        "\n",
        "print(\"\\nEmbedding Matrix (CBOW):\")\n",
        "print(embedding_matrix_cbow)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go7JBusPXSUZ",
        "outputId": "2470ddde-2356-4b2f-8d86-fcc0ebc631fb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Vectors (Skip-gram):\n",
            "var [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
            "nan [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "*/ [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "  7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            " -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "  9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "  5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            " -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "  7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            " -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            " -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            " -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "  3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            " -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            " -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            " -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "  4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            " -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            " -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "  4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "  9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "  1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "  1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "  8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "  9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            "Apache-2.0 [-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
            "  4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
            "  6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
            "  3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
            "  8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
            "  1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
            " -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
            "  2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
            " -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
            "  9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
            "  3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
            "  7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
            " -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
            " -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
            "  1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
            "  2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
            "  4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
            " -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
            " -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
            " -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
            " -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
            " -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
            " -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
            " -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
            "  5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n",
            "SPDX-License-Identifier: [-0.00713902  0.00124103 -0.00717672 -0.00224462  0.0037193   0.00583312\n",
            "  0.00119818  0.00210273 -0.00411039  0.00722533 -0.00630704  0.00464722\n",
            " -0.00821997  0.00203647 -0.00497705 -0.00424769 -0.00310898  0.00565521\n",
            "  0.0057984  -0.00497465  0.00077333 -0.00849578  0.00780981  0.00925729\n",
            " -0.00274233  0.00080022  0.00074665  0.00547788 -0.00860608  0.00058446\n",
            "  0.00686942  0.00223159  0.00112468 -0.00932216  0.00848237 -0.00626413\n",
            " -0.00299237  0.00349379 -0.00077263  0.00141129  0.00178199 -0.0068289\n",
            " -0.00972481  0.00904058  0.00619805 -0.00691293  0.00340348  0.00020606\n",
            "  0.00475375 -0.00711994  0.00402695  0.00434743  0.00995737 -0.00447374\n",
            " -0.00138926 -0.00731732 -0.00969783 -0.00908026 -0.00102275 -0.00650329\n",
            "  0.00484973 -0.00616403  0.00251919  0.00073944 -0.00339215 -0.00097922\n",
            "  0.00997913  0.00914589 -0.00446183  0.00908303 -0.00564176  0.00593092\n",
            " -0.00309722  0.00343175  0.00301723  0.00690046 -0.00237388  0.00877504\n",
            "  0.00758943 -0.00954765 -0.00800821 -0.0076379   0.00292326 -0.00279472\n",
            " -0.00692952 -0.00812826  0.00830918  0.00199049 -0.00932802 -0.00479272\n",
            "  0.00313674 -0.00471321  0.00528084 -0.00423344  0.0026418  -0.00804569\n",
            "  0.00620989  0.00481889  0.00078719  0.00301345]\n",
            "\n",
            "Word Vectors (CBOW):\n",
            "nan [-5.3599576e-04  2.3618268e-04  5.1031811e-03  9.0090176e-03\n",
            " -9.3027530e-03 -7.1164612e-03  6.4585819e-03  8.9725042e-03\n",
            " -5.0154147e-03 -3.7630494e-03  7.3800110e-03 -1.5335401e-03\n",
            " -4.5365617e-03  6.5539908e-03 -4.8602140e-03 -1.8159003e-03\n",
            "  2.8762536e-03  9.9197880e-04 -8.2847234e-03 -9.4486726e-03\n",
            "  7.3114745e-03  5.0701466e-03  6.7572175e-03  7.6259393e-04\n",
            "  6.3509271e-03 -3.4053151e-03 -9.4652857e-04  5.7682772e-03\n",
            " -7.5214347e-03 -3.9359811e-03 -7.5113443e-03 -9.2991180e-04\n",
            "  9.5379790e-03 -7.3188636e-03 -2.3337910e-03 -1.9379033e-03\n",
            "  8.0769230e-03 -5.9305397e-03  4.5404217e-05 -4.7538253e-03\n",
            " -9.6033132e-03  5.0069895e-03 -8.7594511e-03 -4.3916032e-03\n",
            " -3.5288278e-05 -2.9624463e-04 -7.6610539e-03  9.6144788e-03\n",
            "  4.9819695e-03  9.2328908e-03 -8.1577506e-03  4.4956431e-03\n",
            " -4.1366871e-03  8.2475814e-04  8.4984899e-03 -4.4620214e-03\n",
            "  4.5172949e-03 -6.7869741e-03 -3.5485127e-03  9.3982993e-03\n",
            " -1.5776062e-03  3.2123216e-04 -4.1406881e-03 -7.6823980e-03\n",
            " -1.5080689e-03  2.4698614e-03 -8.8797597e-04  5.5332640e-03\n",
            " -2.7428227e-03  2.2602386e-03  5.4554595e-03  8.3457706e-03\n",
            " -1.4536596e-03 -9.2080878e-03  4.3704626e-03  5.7188864e-04\n",
            "  7.4417931e-03 -8.1343576e-04 -2.6381763e-03 -8.7527670e-03\n",
            " -8.5639174e-04  2.8263086e-03  5.4011326e-03  7.0523489e-03\n",
            " -5.7028886e-03  1.8588277e-03  6.0884240e-03 -4.7980226e-03\n",
            " -3.1070989e-03  6.7976434e-03  1.6316123e-03  1.8993816e-04\n",
            "  3.4735398e-03  2.1783641e-04  9.6182497e-03  5.0604437e-03\n",
            " -8.9172395e-03 -7.0411288e-03  9.0149010e-04  6.3924603e-03]\n",
            "var [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            "not [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "  7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            " -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "  9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "  5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            " -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "  7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            " -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            " -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            " -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            " -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "  3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            " -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            " -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            " -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "  4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            " -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            " -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "  4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "  9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "  1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "  1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "  8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "  9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "  5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            "*/ [-8.2427636e-03  9.2994273e-03 -1.9734078e-04 -1.9667214e-03\n",
            "  4.6030735e-03 -4.0957900e-03  2.7435382e-03  6.9405753e-03\n",
            "  6.0651479e-03 -7.5110784e-03  9.3828738e-03  4.6717408e-03\n",
            "  3.9658598e-03 -6.2431321e-03  8.4597263e-03 -2.1502927e-03\n",
            "  8.8254241e-03 -5.3619738e-03 -8.1299916e-03  6.8240068e-03\n",
            "  1.6716636e-03 -2.1982035e-03  9.5140859e-03  9.4939619e-03\n",
            " -9.7737079e-03  2.5050298e-03  6.1566713e-03  3.8728439e-03\n",
            "  2.0223262e-03  4.3025654e-04  6.7316263e-04 -3.8207187e-03\n",
            " -7.1396944e-03 -2.0893463e-03  3.9237752e-03  8.8186162e-03\n",
            "  9.2597166e-03 -5.9763473e-03 -9.4027268e-03  9.7641386e-03\n",
            "  3.4292014e-03  5.1664650e-03  6.2818327e-03 -2.8045566e-03\n",
            "  7.3227473e-03  2.8302707e-03  2.8705399e-03 -2.3797792e-03\n",
            " -3.1279556e-03 -2.3695750e-03  4.2759497e-03  7.6341508e-05\n",
            " -9.5845992e-03 -9.6655525e-03 -6.1476971e-03 -1.2885142e-04\n",
            "  1.9977130e-03  9.4315987e-03  5.5841622e-03 -4.2901314e-03\n",
            "  2.7821911e-04  4.9644099e-03  7.6980973e-03 -1.1447142e-03\n",
            "  4.3233526e-03 -5.8142603e-03 -8.0425158e-04  8.1004500e-03\n",
            " -2.3602524e-03 -9.6633732e-03  5.7796403e-03 -3.9293212e-03\n",
            " -1.2229719e-03  9.9799996e-03 -2.2560896e-03 -4.7570583e-03\n",
            " -5.3289519e-03  6.9808825e-03 -5.7090740e-03  2.1131248e-03\n",
            " -5.2557467e-03  6.1209304e-03  4.3576742e-03  2.6068154e-03\n",
            " -1.4914514e-03 -2.7459636e-03  8.9933760e-03  5.2155051e-03\n",
            " -2.1627289e-03 -9.4699413e-03 -7.4259955e-03 -1.0637360e-03\n",
            " -7.9473335e-04 -2.5629115e-03  9.6833864e-03 -4.5820483e-04\n",
            "  5.8732363e-03 -7.4480772e-03 -2.5060328e-03 -5.5494956e-03]\n",
            "Apache-2.0 [-0.00713924  0.00124128 -0.00717656 -0.00224439  0.00371913  0.0058328\n",
            "  0.00119845  0.00210319 -0.00411039  0.00722502 -0.00630657  0.00464729\n",
            " -0.00822001  0.00203651 -0.00497699 -0.0042478  -0.00310867  0.0056551\n",
            "  0.00579794 -0.00497477  0.0007736  -0.00849568  0.00781026  0.00925756\n",
            " -0.00274238  0.00080018  0.00074678  0.00547816 -0.00860626  0.00058434\n",
            "  0.00686921  0.00223147  0.00112479 -0.00932244  0.00848239 -0.00626396\n",
            " -0.00299189  0.00349345 -0.00077287  0.00141139  0.00178178 -0.00682861\n",
            " -0.00972492  0.00904038  0.00619824 -0.00691286  0.00340332  0.0002063\n",
            "  0.00475382 -0.00711972  0.00402681  0.00434758  0.009957   -0.00447396\n",
            " -0.00138916 -0.00731746 -0.00969764 -0.00908023 -0.00102272 -0.00650311\n",
            "  0.00484969 -0.00616389  0.00251925  0.00073917 -0.00339209 -0.0009793\n",
            "  0.00997908  0.00914626 -0.00446197  0.00908285 -0.00564145  0.00593108\n",
            " -0.00309729  0.00343172  0.0030173   0.00690036 -0.00237379  0.00877519\n",
            "  0.0075892  -0.00954786 -0.00800837 -0.00763765  0.00292354 -0.00279444\n",
            " -0.00692974 -0.00812828  0.0083096   0.00199047 -0.00932817 -0.00479275\n",
            "  0.0031366  -0.00471323  0.00528093 -0.0042335   0.00264234 -0.00804554\n",
            "  0.00620976  0.00481848  0.00078716  0.0030135 ]\n",
            "SPDX-License-Identifier: [-8.7274825e-03  2.1301615e-03 -8.7354420e-04 -9.3190884e-03\n",
            " -9.4281426e-03 -1.4107180e-03  4.4324086e-03  3.7040710e-03\n",
            " -6.4986930e-03 -6.8730675e-03 -4.9994122e-03 -2.2868442e-03\n",
            " -7.2502876e-03 -9.6033178e-03 -2.7436293e-03 -8.3628409e-03\n",
            " -6.0388758e-03 -5.6709289e-03 -2.3441375e-03 -1.7069972e-03\n",
            " -8.9569986e-03 -7.3519943e-04  8.1525063e-03  7.6904297e-03\n",
            " -7.2061159e-03 -3.6668312e-03  3.1185520e-03 -9.5707225e-03\n",
            "  1.4764392e-03  6.5244664e-03  5.7464195e-03 -8.7630618e-03\n",
            " -4.5171441e-03 -8.1401607e-03  4.5956374e-05  9.2636338e-03\n",
            "  5.9733056e-03  5.0673080e-03  5.0610625e-03 -3.2429171e-03\n",
            "  9.5521836e-03 -7.3564244e-03 -7.2703874e-03 -2.2653891e-03\n",
            " -7.7856064e-04 -3.2161034e-03 -5.9258583e-04  7.4888230e-03\n",
            " -6.9751858e-04 -1.6249407e-03  2.7443992e-03 -8.3591007e-03\n",
            "  7.8558037e-03  8.5361041e-03 -9.5840869e-03  2.4462664e-03\n",
            "  9.9049713e-03 -7.6658037e-03 -6.9669187e-03 -7.7365171e-03\n",
            "  8.3959233e-03 -6.8133592e-04  9.1444086e-03 -8.1582209e-03\n",
            "  3.7430846e-03  2.6350426e-03  7.4271322e-04  2.3276759e-03\n",
            " -7.4690939e-03 -9.3583735e-03  2.3545765e-03  6.1484552e-03\n",
            "  7.9856887e-03  5.7358947e-03 -7.7733636e-04  8.3061643e-03\n",
            " -9.3363142e-03  3.4061326e-03  2.6675343e-04  3.8572443e-03\n",
            "  7.3857834e-03 -6.7251669e-03  5.5844807e-03 -9.5222248e-03\n",
            " -8.0445886e-04 -8.6887367e-03 -5.0986730e-03  9.2892265e-03\n",
            " -1.8582619e-03  2.9144264e-03  9.0712793e-03  8.9381328e-03\n",
            " -8.2084350e-03 -3.0123137e-03  9.8866057e-03  5.1044310e-03\n",
            " -1.5880871e-03 -8.6920215e-03  2.9615164e-03 -6.6758976e-03]\n",
            "\n",
            "Embedding Matrix (Skip-gram):\n",
            "[[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            "  -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            "  -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            "  -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "   2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "   7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "   6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            "  -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "   9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "   8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            "  -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            "  -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "   4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            "  -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "   4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            "  -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            "  -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            "  -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            "  -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "   7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            "  -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            "  -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            "  -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "   3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            "  -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
            " [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "   7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            "  -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            "  -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "   6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "   2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "   6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            "  -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            "  -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "   6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "   7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            "  -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "   1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            "  -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "   9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            "  -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "   3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "   7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "   5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            "  -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            "  -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "   1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "   2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "   2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "   5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            " [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "   7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            "  -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "   9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "   5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            "  -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "   7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            "  -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            "  -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            "  -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            "  -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "   3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            "  -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            "  -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            "  -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "   4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            "  -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            "  -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "   4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "   9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "   1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "   1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "   8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "   9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "   5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            " [-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
            "   4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
            "   6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
            "   3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
            "   8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
            "   1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
            "  -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
            "   2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
            "  -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
            "   9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
            "   3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
            "   7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
            "  -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
            "  -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
            "   1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
            "   2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
            "   4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
            "  -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
            "  -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
            "  -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
            "  -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
            "  -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
            "  -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
            "  -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
            "   5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n",
            " [-7.1390150e-03  1.2410306e-03 -7.1767163e-03 -2.2446180e-03\n",
            "   3.7193035e-03  5.8331238e-03  1.1981833e-03  2.1027315e-03\n",
            "  -4.1103913e-03  7.2253332e-03 -6.3070417e-03  4.6472158e-03\n",
            "  -8.2199732e-03  2.0364679e-03 -4.9770521e-03 -4.2476882e-03\n",
            "  -3.1089843e-03  5.6552086e-03  5.7984008e-03 -4.9746488e-03\n",
            "   7.7333092e-04 -8.4957778e-03  7.8098057e-03  9.2572914e-03\n",
            "  -2.7423275e-03  8.0022332e-04  7.4665190e-04  5.4778848e-03\n",
            "  -8.6060790e-03  5.8445573e-04  6.8694223e-03  2.2315944e-03\n",
            "   1.1246764e-03 -9.3221553e-03  8.4823668e-03 -6.2641273e-03\n",
            "  -2.9923737e-03  3.4937870e-03 -7.7262759e-04  1.4112913e-03\n",
            "   1.7819917e-03 -6.8288995e-03 -9.7248117e-03  9.0405848e-03\n",
            "   6.1980546e-03 -6.9129276e-03  3.4034825e-03  2.0606398e-04\n",
            "   4.7537456e-03 -7.1199429e-03  4.0269541e-03  4.3474343e-03\n",
            "   9.9573694e-03 -4.4737398e-03 -1.3892639e-03 -7.3173214e-03\n",
            "  -9.6978294e-03 -9.0802573e-03 -1.0227549e-03 -6.5032900e-03\n",
            "   4.8497282e-03 -6.1640264e-03  2.5191857e-03  7.3944090e-04\n",
            "  -3.3921539e-03 -9.7922329e-04  9.9791251e-03  9.1458866e-03\n",
            "  -4.4618296e-03  9.0830270e-03 -5.6417631e-03  5.9309220e-03\n",
            "  -3.0972182e-03  3.4317516e-03  3.0172265e-03  6.9004609e-03\n",
            "  -2.3738837e-03  8.7750368e-03  7.5894282e-03 -9.5476462e-03\n",
            "  -8.0082091e-03 -7.6378966e-03  2.9232574e-03 -2.7947223e-03\n",
            "  -6.9295205e-03 -8.1282640e-03  8.3091799e-03  1.9904887e-03\n",
            "  -9.3280170e-03 -4.7927164e-03  3.1367384e-03 -4.7132061e-03\n",
            "   5.2808430e-03 -4.2334413e-03  2.6417959e-03 -8.0456873e-03\n",
            "   6.2098862e-03  4.8188888e-03  7.8719261e-04  3.0134476e-03]]\n",
            "\n",
            "Embedding Matrix (CBOW):\n",
            "[[-5.3599576e-04  2.3618268e-04  5.1031811e-03  9.0090176e-03\n",
            "  -9.3027530e-03 -7.1164612e-03  6.4585819e-03  8.9725042e-03\n",
            "  -5.0154147e-03 -3.7630494e-03  7.3800110e-03 -1.5335401e-03\n",
            "  -4.5365617e-03  6.5539908e-03 -4.8602140e-03 -1.8159003e-03\n",
            "   2.8762536e-03  9.9197880e-04 -8.2847234e-03 -9.4486726e-03\n",
            "   7.3114745e-03  5.0701466e-03  6.7572175e-03  7.6259393e-04\n",
            "   6.3509271e-03 -3.4053151e-03 -9.4652857e-04  5.7682772e-03\n",
            "  -7.5214347e-03 -3.9359811e-03 -7.5113443e-03 -9.2991180e-04\n",
            "   9.5379790e-03 -7.3188636e-03 -2.3337910e-03 -1.9379033e-03\n",
            "   8.0769230e-03 -5.9305397e-03  4.5404217e-05 -4.7538253e-03\n",
            "  -9.6033132e-03  5.0069895e-03 -8.7594511e-03 -4.3916032e-03\n",
            "  -3.5288278e-05 -2.9624463e-04 -7.6610539e-03  9.6144788e-03\n",
            "   4.9819695e-03  9.2328908e-03 -8.1577506e-03  4.4956431e-03\n",
            "  -4.1366871e-03  8.2475814e-04  8.4984899e-03 -4.4620214e-03\n",
            "   4.5172949e-03 -6.7869741e-03 -3.5485127e-03  9.3982993e-03\n",
            "  -1.5776062e-03  3.2123216e-04 -4.1406881e-03 -7.6823980e-03\n",
            "  -1.5080689e-03  2.4698614e-03 -8.8797597e-04  5.5332640e-03\n",
            "  -2.7428227e-03  2.2602386e-03  5.4554595e-03  8.3457706e-03\n",
            "  -1.4536596e-03 -9.2080878e-03  4.3704626e-03  5.7188864e-04\n",
            "   7.4417931e-03 -8.1343576e-04 -2.6381763e-03 -8.7527670e-03\n",
            "  -8.5639174e-04  2.8263086e-03  5.4011326e-03  7.0523489e-03\n",
            "  -5.7028886e-03  1.8588277e-03  6.0884240e-03 -4.7980226e-03\n",
            "  -3.1070989e-03  6.7976434e-03  1.6316123e-03  1.8993816e-04\n",
            "   3.4735398e-03  2.1783641e-04  9.6182497e-03  5.0604437e-03\n",
            "  -8.9172395e-03 -7.0411288e-03  9.0149010e-04  6.3924603e-03]\n",
            " [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
            "   7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
            "  -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
            "  -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
            "   6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
            "   2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
            "   6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
            "  -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
            "  -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
            "   6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
            "   7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
            "  -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
            "   1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
            "  -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
            "   9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
            "  -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
            "   3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
            "   7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
            "   5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
            "  -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
            "  -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
            "   1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
            "   2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
            "   2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
            "   5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n",
            " [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "   7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            "  -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "   9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "   5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            "  -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "   7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            "  -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            "  -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            "  -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            "  -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "   3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            "  -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            "  -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            "  -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "   4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            "  -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            "  -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "   4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "   9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "   1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "   1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "   8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "   9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "   5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]\n",
            " [-8.2427636e-03  9.2994273e-03 -1.9734078e-04 -1.9667214e-03\n",
            "   4.6030735e-03 -4.0957900e-03  2.7435382e-03  6.9405753e-03\n",
            "   6.0651479e-03 -7.5110784e-03  9.3828738e-03  4.6717408e-03\n",
            "   3.9658598e-03 -6.2431321e-03  8.4597263e-03 -2.1502927e-03\n",
            "   8.8254241e-03 -5.3619738e-03 -8.1299916e-03  6.8240068e-03\n",
            "   1.6716636e-03 -2.1982035e-03  9.5140859e-03  9.4939619e-03\n",
            "  -9.7737079e-03  2.5050298e-03  6.1566713e-03  3.8728439e-03\n",
            "   2.0223262e-03  4.3025654e-04  6.7316263e-04 -3.8207187e-03\n",
            "  -7.1396944e-03 -2.0893463e-03  3.9237752e-03  8.8186162e-03\n",
            "   9.2597166e-03 -5.9763473e-03 -9.4027268e-03  9.7641386e-03\n",
            "   3.4292014e-03  5.1664650e-03  6.2818327e-03 -2.8045566e-03\n",
            "   7.3227473e-03  2.8302707e-03  2.8705399e-03 -2.3797792e-03\n",
            "  -3.1279556e-03 -2.3695750e-03  4.2759497e-03  7.6341508e-05\n",
            "  -9.5845992e-03 -9.6655525e-03 -6.1476971e-03 -1.2885142e-04\n",
            "   1.9977130e-03  9.4315987e-03  5.5841622e-03 -4.2901314e-03\n",
            "   2.7821911e-04  4.9644099e-03  7.6980973e-03 -1.1447142e-03\n",
            "   4.3233526e-03 -5.8142603e-03 -8.0425158e-04  8.1004500e-03\n",
            "  -2.3602524e-03 -9.6633732e-03  5.7796403e-03 -3.9293212e-03\n",
            "  -1.2229719e-03  9.9799996e-03 -2.2560896e-03 -4.7570583e-03\n",
            "  -5.3289519e-03  6.9808825e-03 -5.7090740e-03  2.1131248e-03\n",
            "  -5.2557467e-03  6.1209304e-03  4.3576742e-03  2.6068154e-03\n",
            "  -1.4914514e-03 -2.7459636e-03  8.9933760e-03  5.2155051e-03\n",
            "  -2.1627289e-03 -9.4699413e-03 -7.4259955e-03 -1.0637360e-03\n",
            "  -7.9473335e-04 -2.5629115e-03  9.6833864e-03 -4.5820483e-04\n",
            "   5.8732363e-03 -7.4480772e-03 -2.5060328e-03 -5.5494956e-03]\n",
            " [-7.1392418e-03  1.2412751e-03 -7.1765631e-03 -2.2443889e-03\n",
            "   3.7191326e-03  5.8327988e-03  1.1984534e-03  2.1031864e-03\n",
            "  -4.1103922e-03  7.2250250e-03 -6.3065737e-03  4.6472875e-03\n",
            "  -8.2200123e-03  2.0365117e-03 -4.9769869e-03 -4.2477995e-03\n",
            "  -3.1086702e-03  5.6551024e-03  5.7979366e-03 -4.9747676e-03\n",
            "   7.7360013e-04 -8.4956763e-03  7.8102578e-03  9.2575569e-03\n",
            "  -2.7423799e-03  8.0018170e-04  7.4677955e-04  5.4781623e-03\n",
            "  -8.6062606e-03  5.8434473e-04  6.8692067e-03  2.2314682e-03\n",
            "   1.1247899e-03 -9.3224356e-03  8.4823947e-03 -6.2639625e-03\n",
            "  -2.9918873e-03  3.4934508e-03 -7.7286595e-04  1.4113931e-03\n",
            "   1.7817816e-03 -6.8286126e-03 -9.7249225e-03  9.0403771e-03\n",
            "   6.1982404e-03 -6.9128647e-03  3.4033183e-03  2.0630122e-04\n",
            "   4.7538201e-03 -7.1197171e-03  4.0268102e-03  4.3475754e-03\n",
            "   9.9569969e-03 -4.4739605e-03 -1.3891574e-03 -7.3174629e-03\n",
            "  -9.6976385e-03 -9.0802275e-03 -1.0227225e-03 -6.5031084e-03\n",
            "   4.8496863e-03 -6.1638900e-03  2.5192536e-03  7.3917367e-04\n",
            "  -3.3920903e-03 -9.7929500e-04  9.9790767e-03  9.1462648e-03\n",
            "  -4.4619748e-03  9.0828510e-03 -5.6414464e-03  5.9310803e-03\n",
            "  -3.0972944e-03  3.4317209e-03  3.0173045e-03  6.9003575e-03\n",
            "  -2.3737890e-03  8.7751895e-03  7.5892010e-03 -9.5478632e-03\n",
            "  -8.0083692e-03 -7.6376530e-03  2.9235359e-03 -2.7944373e-03\n",
            "  -6.9297352e-03 -8.1282761e-03  8.3095981e-03  1.9904731e-03\n",
            "  -9.3281688e-03 -4.7927471e-03  3.1365997e-03 -4.7132275e-03\n",
            "   5.2809305e-03 -4.2335000e-03  2.6423410e-03 -8.0455421e-03\n",
            "   6.2097595e-03  4.8184809e-03  7.8715663e-04  3.0135042e-03]\n",
            " [-8.7274825e-03  2.1301615e-03 -8.7354420e-04 -9.3190884e-03\n",
            "  -9.4281426e-03 -1.4107180e-03  4.4324086e-03  3.7040710e-03\n",
            "  -6.4986930e-03 -6.8730675e-03 -4.9994122e-03 -2.2868442e-03\n",
            "  -7.2502876e-03 -9.6033178e-03 -2.7436293e-03 -8.3628409e-03\n",
            "  -6.0388758e-03 -5.6709289e-03 -2.3441375e-03 -1.7069972e-03\n",
            "  -8.9569986e-03 -7.3519943e-04  8.1525063e-03  7.6904297e-03\n",
            "  -7.2061159e-03 -3.6668312e-03  3.1185520e-03 -9.5707225e-03\n",
            "   1.4764392e-03  6.5244664e-03  5.7464195e-03 -8.7630618e-03\n",
            "  -4.5171441e-03 -8.1401607e-03  4.5956374e-05  9.2636338e-03\n",
            "   5.9733056e-03  5.0673080e-03  5.0610625e-03 -3.2429171e-03\n",
            "   9.5521836e-03 -7.3564244e-03 -7.2703874e-03 -2.2653891e-03\n",
            "  -7.7856064e-04 -3.2161034e-03 -5.9258583e-04  7.4888230e-03\n",
            "  -6.9751858e-04 -1.6249407e-03  2.7443992e-03 -8.3591007e-03\n",
            "   7.8558037e-03  8.5361041e-03 -9.5840869e-03  2.4462664e-03\n",
            "   9.9049713e-03 -7.6658037e-03 -6.9669187e-03 -7.7365171e-03\n",
            "   8.3959233e-03 -6.8133592e-04  9.1444086e-03 -8.1582209e-03\n",
            "   3.7430846e-03  2.6350426e-03  7.4271322e-04  2.3276759e-03\n",
            "  -7.4690939e-03 -9.3583735e-03  2.3545765e-03  6.1484552e-03\n",
            "   7.9856887e-03  5.7358947e-03 -7.7733636e-04  8.3061643e-03\n",
            "  -9.3363142e-03  3.4061326e-03  2.6675343e-04  3.8572443e-03\n",
            "   7.3857834e-03 -6.7251669e-03  5.5844807e-03 -9.5222248e-03\n",
            "  -8.0445886e-04 -8.6887367e-03 -5.0986730e-03  9.2892265e-03\n",
            "  -1.8582619e-03  2.9144264e-03  9.0712793e-03  8.9381328e-03\n",
            "  -8.2084350e-03 -3.0123137e-03  9.8866057e-03  5.1044310e-03\n",
            "  -1.5880871e-03 -8.6920215e-03  2.9615164e-03 -6.6758976e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "\n",
        "# Extract the paragraphs, questions, answers from the dataframe\n",
        "paragraphs = df['1'].astype(str).tolist()\n",
        "questions = df['2'].astype(str).tolist()\n",
        "answers = df['3'].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers into a single corpus\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
        "\n",
        "# Train Word2Vec model\n",
        "cbow_model = Word2Vec(tokenized_corpus, vector_size=100, window=5, sg=0, min_count=1)"
      ],
      "metadata": {
        "id": "iu4cDY9uYbYk"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "\n",
        "# Extract the paragraphs, questions, answers from the dataframe\n",
        "paragraphs = df['1'].astype(str).tolist()\n",
        "questions = df['2'].astype(str).tolist()\n",
        "answers = df['3'].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers into a single corpus\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
        "\n",
        "# Train Word2Vec model\n",
        "cbow_model = Word2Vec(tokenized_corpus, vector_size=100, window=5, sg=0, min_count=1)\n",
        "\n",
        "# Create training data\n",
        "X_train = tokenized_corpus\n",
        "y_train = [0] * len(tokenized_corpus)"
      ],
      "metadata": {
        "id": "rz7gpUW0ZkVX"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Load the dataset from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)], skiprows=6)\n",
        "\n",
        "# Extract the paragraphs, questions, answers from the dataframe\n",
        "paragraphs = df['1'].astype(str).tolist()\n",
        "questions = df['2'].astype(str).tolist()\n",
        "answers = df['3'].astype(str).tolist()\n",
        "\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
        "\n",
        "# Train Word2Vec model\n",
        "cbow_model = Word2Vec(tokenized_corpus, vector_size=100, window=5, sg=0, min_count=1)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iuaAuZ1ncx3W"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Dummy data for demonstration\n",
        "X_train = np.random.rand(100, 10)\n",
        "y_train = np.random.randint(0, 2, size=(100,))\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_shape=(10,)))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "try:\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "except Exception as e:\n",
        "    print(\"An error occurred during model training:\")\n",
        "    print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nok_DrueaKAu",
        "outputId": "ae92ecc9-93f0-4858-a184-2506eebde31a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 0.7022 - accuracy: 0.5100\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.5100\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5200\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5100\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5300\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.4900\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5200\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.4900\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5100\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "\n",
        "# Adjust the file path and extension if necessary\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)])\n",
        "\n",
        "# Check for the existence of the 'Paragraph', 'Question', and 'Answer' columns\n",
        "if 'Paragraph' not in df.columns:\n",
        "    print(\"The 'Paragraph' column is not found in the DataFrame.\")\n",
        "if 'Question' not in df.columns:\n",
        "    print(\"The 'Question' column is not found in the DataFrame.\")\n",
        "if 'Answer' not in df.columns:\n",
        "    print(\"The 'Answer' column is not found in the DataFrame.\")\n",
        "\n",
        "# Extract the paragraphs, questions, and answers from the dataframe\n",
        "paragraphs = df['Paragraph'].astype(str).tolist() if 'Paragraph' in df.columns else []\n",
        "questions = df['Question'].astype(str).tolist() if 'Question' in df.columns else []\n",
        "answers = df['Answer'].astype(str).tolist() if 'Answer' in df.columns else []\n",
        "\n",
        "# Combine paragraphs, questions, and answers\n",
        "corpus = paragraphs + questions + answers\n",
        "\n",
        "# Tokenize the corpus into words\n",
        "tokenized_corpus = [sentence.split() if isinstance(sentence, str) else [] for sentence in corpus]\n",
        "\n",
        "# Create training data for skip-gram\n",
        "skip_gram_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    skip_gram_data.extend(word2vec.LineSentence(paragraphs[i]))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQW4FvRvgAPt",
        "outputId": "c659c894-dace-4610-cc6f-824810aff3b8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'Paragraph' column is not found in the DataFrame.\n",
            "The 'Question' column is not found in the DataFrame.\n",
            "The 'Answer' column is not found in the DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0l9pfbAwikjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JO0dfj28ikyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install gensim\n",
        "!pip install tensorflow\n",
        "!pip install pandas"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVjGvQE0d7_C",
        "outputId": "e5640206-cf00-4034-91d4-8fe217e4b060"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Read data from Excel file\n",
        "df = pd.read_csv('lamb.csv', header=None, names=[str(i) for i in range(1, 3591)])\n",
        "\n",
        "# Handle missing values\n",
        "data.fillna('', inplace=True)\n",
        "\n",
        "# Extract paragraphs, questions, and answers\n",
        "paragraphs = data['Paragraph'].tolist()\n",
        "questions = data['Question'].tolist()\n",
        "answers = data['Answer'].tolist()\n",
        "\n",
        "# Generate training data\n",
        "training_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    paragraph = str(paragraphs[i]).lower().split()\n",
        "    question = str(questions[i]).lower().split()\n",
        "\n",
        "    # Normalization\n",
        "    paragraph = [word.strip() for word in paragraph]\n",
        "    question = [word.strip() for word in question]\n",
        "\n",
        "    # Filter stop words\n",
        "    stop_words = set()\n",
        "    with open('stopwords.txt', 'r') as file:\n",
        "        for line in file:\n",
        "            stop_words.add(line.strip())\n",
        "\n",
        "    paragraph = [word for word in paragraph if word not in stop_words]\n",
        "    question = [word for word in question if word not in stop_words]\n",
        "\n",
        "    training_data.append(paragraph)\n",
        "    training_data.append(question)\n",
        "\n",
        "# Initialize Word2Vec model\n",
        "model = Word2Vec(min_count=1)\n",
        "\n",
        "# Build vocabulary\n",
        "model.build_vocab(training_data)\n",
        "\n",
        "# Train Word2Vec model\n",
        "model.train(training_data, total_examples=model.corpus_count, epochs=10)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"word2vec_model\")\n",
        "\n",
        "# Calculate total characters and vocabulary size\n",
        "n_chars = sum(len(p) for p in paragraphs) + sum(len(q) for q in questions)\n",
        "# Calculate total characters and vocabulary size\n",
        "n_chars = sum(len(p) for p in paragraphs) + sum(len(q) for q in questions)\n",
        "n_vocab = len(model.wv.key_to_index)\n",
        "\n",
        "# Print dataset summary\n",
        "num_paragraphs = len(paragraphs)\n",
        "num_questions = len(questions)\n",
        "num_answers = len(answers)\n",
        "\n",
        "max_paragraph_length = max(len(p) for p in paragraphs)\n",
        "max_question_length = max(len(q) for q in questions)\n",
        "max_answer_length = max(len(a) for a in answers)\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(\"Number of paragraphs:\", num_paragraphs)\n",
        "print(\"Number of questions:\", num_questions)\n",
        "print(\"Number of answers:\", num_answers)\n",
        "print(\"Maximum paragraph length:\", max_paragraph_length)\n",
        "print(\"Maximum question length:\", max_question_length)\n",
        "print(\"Maximum answer length:\", max_answer_length)\n",
        "print(\"Total Characters:\", n_chars)\n",
        "print(\"Total Vocab:\", n_vocab)\n",
        "\n",
        "# Print and save vocabulary\n",
        "vocabulary = list(model.wv.key_to_index.keys())\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "\n",
        "with open(\"vocabulary.txt\", \"w\") as file:\n",
        "    for word in vocabulary:\n",
        "        file.write(word + \"\\n\")\n",
        "        # Display Word2Vec representation\n",
        "for word in model.wv.index_to_key:\n",
        "    print(\"Word:\", word)\n",
        "    print(\"Vector:\", model.wv.get_vector(word))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "sxwlDSLeimaF",
        "outputId": "b7ed30a7-46a8-429b-a711-d46628237652"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-89b6a2f5a6e1>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Extract paragraphs, questions, and answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "source": [
        "# Calculate total characters and vocabulary size\n",
        "n_chars = sum(len(p) for p in paragraphs) + sum(len(q) for q in questions)\n",
        "n_vocab = len(model.wv.key_to_index)\n",
        "\n",
        "# Print dataset summary\n",
        "num_paragraphs = len(paragraphs)\n",
        "num_questions = len(questions)\n",
        "num_answers = len(answers)\n",
        "\n",
        "max_paragraph_length = max(len(p) for p in paragraphs)\n",
        "max_question_length = max(len(q) for q in questions)\n",
        "max_answer_length = max(len(a) for a in answers)\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(\"Number of paragraphs:\", num_paragraphs)\n",
        "print(\"Number of questions:\", num_questions)\n",
        "print(\"Number of answers:\", num_answers)\n",
        "print(\"Maximum paragraph length:\", max_paragraph_length)\n",
        "print(\"Maximum question length:\", max_question_length)\n",
        "print(\"Maximum answer length:\", max_answer_length)\n",
        "print(\"Total Characters:\", n_chars)\n",
        "print(\"Total Vocab:\", n_vocab)\n",
        "\n",
        "# Print and save vocabulary\n",
        "vocabulary = list(model.wv.key_to_index.keys())\n",
        "print(\"Vocabulary:\", vocabulary)\n",
        "\n",
        "with open(\"vocabulary.txt\", \"w\") as file:\n",
        "    for word in vocabulary:\n",
        "        file.write(word + \"\\n\")\n",
        "        # Display Word2Vec representation\n",
        "for word in model.wv.index_to_key:\n",
        "    print(\"Word:\", word)\n",
        "    print(\"Vector:\", model.wv.get_vector(word))\n",
        "    print()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8FOH2jR4koW7",
        "outputId": "08895d88-104f-49fe-8df3-d5b33e8365e5"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'wv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-5f7a94597f0f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate total characters and vocabulary size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparagraphs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Print dataset summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'wv'"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install xlrd"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz_KFIJ9djdC",
        "outputId": "8b4d8bb0-0869-4cd4-859b-67cd3851ffce"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Read data from Excel file\n",
        "data = pd.read_excel('lamb.xlsx')\n",
        "\n",
        "# Handle missing values\n",
        "data.fillna('', inplace=True)\n",
        "\n",
        "# Extract paragraphs, questions, and answers\n",
        "paragraphs = data['Paragraph'].tolist()\n",
        "questions = data['Question'].tolist()\n",
        "answers = data['Answer'].tolist()\n",
        "\n",
        "# Generate training data\n",
        "training_data = []\n",
        "for i in range(len(paragraphs)):\n",
        "    paragraph = str(paragraphs[i]).lower().split()\n",
        "    question = str(questions[i]).lower().split()\n",
        "\n",
        "    # Normalization\n",
        "    paragraph = [word.strip() for word in paragraph]\n",
        "    question = [word.strip() for word in question]\n",
        "\n",
        "    # Filter stop words\n",
        "    stop_words = set()\n",
        "    with open('stopwords.txt', 'r') as file:\n",
        "        for line in file:\n",
        "            stop_words.add(line.strip())\n",
        "    paragraph = [word for word in paragraph if word not in stop_words]\n",
        "    question = [word for word in question if word not in stop_words]\n",
        "\n",
        "    training_data.append((paragraph, question))\n",
        "\n",
        "# Create a vocabulary\n",
        "vocab = set()\n",
        "for paragraph, question in training_data:\n",
        "    vocab.update(paragraph)\n",
        "    vocab.update(question)\n",
        "\n",
        "# Create one-hot encoding for each word in the vocabulary\n",
        "word_to_index = {word: index for index, word in enumerate(vocab)}\n",
        "index_to_word = {index: word for index, word in enumerate(vocab)}\n",
        "\n",
        "# Convert training data to one-hot encoded vectors\n",
        "encoded_data = []\n",
        "for paragraph, question in training_data:\n",
        "    paragraph_encoded = [0] * len(vocab)\n",
        "    question_encoded = [0] * len(vocab)\n",
        "    for word in paragraph:\n",
        "        if word in word_to_index:\n",
        "            paragraph_encoded[word_to_index[word]] = 1\n",
        "    for word in question:\n",
        "        if word in word_to_index:\n",
        "            question_encoded[word_to_index[word]] = 1\n",
        "    encoded_data.append((paragraph_encoded, question_encoded))\n",
        "\n",
        "# Initialize Word2Vec model\n",
        "model = Word2Vec(min_count=1)\n",
        "\n",
        "# Build vocabulary\n",
        "model.build_vocab_from_freq(word_to_index)\n",
        "\n",
        "# Train Word2Vec model\n",
        "model.train(encoded_data, total_examples=len(encoded_data), epochs=10)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"word2vec_model\")\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_size = int(0.8 * len(encoded_data))\n",
        "train_data = encoded_data[:train_size]\n",
        "test_data = encoded_data[train_size:]\n",
        "\n",
        "# Convert train and test sets to DataFrames\n",
        "train_df = pd.DataFrame(train_data, columns=['paragraph', 'question'])\n",
        "test_df = pd.DataFrame(test_data, columns=['paragraph', 'question'])\n",
        "\n",
        "# Save train and test sets as separate files\n",
        "train_df.to_csv(\"train_data.csv\", index=False)\n",
        "test_df.to_csv(\"test_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Koua9eygk300"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Read data from Excel file\n",
        "data = pd.read_excel('lamb.xlsx', engine='openpyxl')\n",
        "\n",
        "# Extract paragraphs, questions, and answers\n",
        "paragraphs = data['Paragraph'].tolist()\n",
        "questions = data['Question'].tolist()\n",
        "answers = data['Answer'].tolist()\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(paragraphs + questions)  # Combine paragraphs and questions for tokenization\n",
        "context_seqs = tokenizer.texts_to_sequences(paragraphs)\n",
        "question_seqs = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "# Padding sequences for input to RNN\n",
        "max_seq_length = max(max(len(seq) for seq in context_seqs), max(len(seq) for seq in question_seqs))\n",
        "context_padded = pad_sequences(context_seqs, maxlen=max_seq_length, padding='post')\n",
        "question_padded = pad_sequences(question_seqs, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(context_padded, question_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, X_train and y_train contain the context-question pairs for training the RNN model\n"
      ],
      "metadata": {
        "id": "bhIcgdYJk4-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences for input to RNN with a consistent length\n",
        "max_seq_length = 100  # Choose an appropriate sequence length\n",
        "paragraphs_padded = pad_sequences(paragraphs_seq, maxlen=max_seq_length, padding='post')\n",
        "questions_padded = pad_sequences(questions_seq, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Define and build the RNN model for question generation with adjusted input shape\n",
        "model_rnn = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_seq_length),\n",
        "    LSTM(units=128),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the RNN model with appropriate loss function\n",
        "model_rnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the RNN model with the padded input data\n",
        "model_rnn.fit(paragraphs_padded, questions_padded, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "Yv4sgcyRlAFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for RNN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Tokenize the input data for RNN\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(paragraphs + questions)  # Combine paragraphs and questions for tokenization\n",
        "paragraphs_seq = tokenizer.texts_to_sequences(paragraphs)\n",
        "questions_seq = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "# Pad sequences for input to RNN\n",
        "max_seq_length = max(max(len(seq) for seq in paragraphs_seq), max(len(seq) for seq in questions_seq))\n",
        "paragraphs_padded = pad_sequences(paragraphs_seq, maxlen=max_seq_length, padding='post')\n",
        "questions_padded = pad_sequences(questions_seq, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Define and build the RNN model for question generation\n",
        "model_rnn = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_seq_length),\n",
        "    LSTM(units=128),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the RNN model\n",
        "model_rnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the RNN model\n",
        "model_rnn.fit(paragraphs_padded, questions_padded, epochs=10, batch_size=32)\n",
        "\n",
        "# Generate questions using the trained RNN model\n",
        "# Add code to generate questions here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "2mtLDs2XlG6J",
        "outputId": "5ad30001-25a0-40c1-a485-33bbc2c74978"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-ae7c27b467e6>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Pad sequences for input to RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparagraphs_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mparagraphs_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraphs_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mquestions_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    }
  ]
}